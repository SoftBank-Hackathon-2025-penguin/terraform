ì™„ì „í•œ README ë¬¸ì„œë¥¼ ì‘ì„±í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.[1][2][3]

# README.md

```markdown
# Terraform AWS Infrastructure Builder

í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì„ íƒí•œ AWS ë¦¬ì†ŒìŠ¤ë¥¼ ìë™ìœ¼ë¡œ ìƒì„±í•˜ê³  ì—°ê²°í•˜ëŠ” ëª¨ë“ˆí˜• Terraform í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤[web:1][web:89].

## ğŸ“‹ ëª©ì°¨

- [ê°œìš”](#ê°œìš”)
- [ì§€ì›í•˜ëŠ” AWS ì„œë¹„ìŠ¤](#ì§€ì›í•˜ëŠ”-aws-ì„œë¹„ìŠ¤)
- [ì‚¬ì „ ìš”êµ¬ì‚¬í•­](#ì‚¬ì „-ìš”êµ¬ì‚¬í•­)
- [í”„ë¡œì íŠ¸ êµ¬ì¡°](#í”„ë¡œì íŠ¸-êµ¬ì¡°)
- [ë¹ ë¥¸ ì‹œì‘](#ë¹ ë¥¸-ì‹œì‘)
- [ê°œë³„ ì„œë¹„ìŠ¤ ìƒì„± ë°©ë²•](#ê°œë³„-ì„œë¹„ìŠ¤-ìƒì„±-ë°©ë²•)
- [íŒŒë¼ë¯¸í„° ìƒì„¸ ì„¤ëª…](#íŒŒë¼ë¯¸í„°-ìƒì„¸-ì„¤ëª…)
- [ì—°ê²°ëœ ì¸í”„ë¼ ìƒì„± ì˜ˆì‹œ](#ì—°ê²°ëœ-ì¸í”„ë¼-ìƒì„±-ì˜ˆì‹œ)
- [ê³ ê¸‰ ì‚¬ìš©ë²•](#ê³ ê¸‰-ì‚¬ìš©ë²•)
- [íŠ¸ëŸ¬ë¸”ìŠˆíŒ…](#íŠ¸ëŸ¬ë¸”ìŠˆíŒ…)
- [ë¼ì´ì„¼ìŠ¤](#ë¼ì´ì„¼ìŠ¤)

---

## ê°œìš”

ì´ í”„ë¡œì íŠ¸ëŠ” **ëª¨ë“ˆí˜• Terraform êµ¬ì„±**ìœ¼ë¡œ ì„¤ê³„ë˜ì–´ ê° AWS ì„œë¹„ìŠ¤ë¥¼ ë…ë¦½ì ìœ¼ë¡œ ë˜ëŠ” ì¡°í•©í•˜ì—¬ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤[web:92].

### ì£¼ìš” íŠ¹ì§•

- âœ… **ì„ íƒì  ë¦¬ì†ŒìŠ¤ ìƒì„±**: í•„ìš”í•œ ì„œë¹„ìŠ¤ë§Œ ì„ íƒí•˜ì—¬ ìƒì„±
- âœ… **ìë™ ì—°ê²° ì„¤ì •**: EC2-S3, EC2-RDS, EC2-CloudWatch ìë™ ì—°ê²°
- âœ… **ë‹¤ì¤‘ ì¸ìŠ¤í„´ìŠ¤ ì§€ì›**: ê° ì„œë¹„ìŠ¤ì˜ ì—¬ëŸ¬ ì¸ìŠ¤í„´ìŠ¤ ë™ì‹œ ìƒì„±
- âœ… **ë³´ì•ˆ ì¤‘ì‹¬ ì„¤ê³„**: ì•”í˜¸í™”, ìµœì†Œ ê¶Œí•œ ì›ì¹™ ì ìš©
- âœ… **í”„ë¡œë•ì…˜ ëŒ€ì‘**: ë°±ì—…, ëª¨ë‹ˆí„°ë§, ì•ŒëŒ ìë™ ì„¤ì •

---

## ì§€ì›í•˜ëŠ” AWS ì„œë¹„ìŠ¤

| ì„œë¹„ìŠ¤ | ë…ë¦½ ìƒì„± | ë‹¤ì¤‘ ì¸ìŠ¤í„´ìŠ¤ | ìë™ ì—°ê²° ëŒ€ìƒ |
|--------|----------|--------------|---------------|
| **VPC** | âœ… | âŒ (1ê°œ) | EC2, RDS, Lambda |
| **EC2** | âš ï¸ (VPC í•„ìš”) | âœ… | S3, RDS, CloudWatch |
| **RDS** | âš ï¸ (VPC í•„ìš”) | âœ… | EC2, S3 |
| **S3** | âœ… | âœ… | EC2, RDS, Lambda |
| **CloudWatch** | âœ… | âŒ (1ê°œ) | EC2, RDS, SNS |
| **SNS** | âœ… | âŒ (1ê°œ) | CloudWatch, Lambda |
| **Lambda** | âœ… | âœ… | S3, SNS, VPC |

---

## ì‚¬ì „ ìš”êµ¬ì‚¬í•­

### í•„ìˆ˜ ë„êµ¬

```
# Terraform ì„¤ì¹˜ í™•ì¸
terraform version
# Terraform v1.5.0 ì´ìƒ í•„ìš”

# AWS CLI ì„¤ì¹˜ ë° êµ¬ì„±
aws --version
aws configure
```

### AWS ìê²©ì¦ëª… ì„¤ì •

```
# AWS Credentials ì„¤ì •
export AWS_ACCESS_KEY_ID="your-access-key"
export AWS_SECRET_ACCESS_KEY="your-secret-key"
export AWS_DEFAULT_REGION="ap-northeast-2"

# ë˜ëŠ” AWS CLIë¡œ ì„¤ì •
aws configure
```

### SSH í‚¤ í˜ì–´ ìƒì„± (EC2 ì‚¬ìš© ì‹œ)

```
aws ec2 create-key-pair \
  --key-name my-terraform-key \
  --query 'KeyMaterial' \
  --output text > ~/.ssh/my-terraform-key.pem

chmod 400 ~/.ssh/my-terraform-key.pem
```

---

## í”„ë¡œì íŠ¸ êµ¬ì¡°

```
terraform-infra-builder/
â”œâ”€â”€ main.tf                      # ë£¨íŠ¸ ëª¨ë“ˆ (ì„œë¹„ìŠ¤ í†µí•©)
â”œâ”€â”€ variables.tf                 # ì „ì—­ ë³€ìˆ˜ ì •ì˜
â”œâ”€â”€ outputs.tf                   # ì¶œë ¥ ê°’
â”œâ”€â”€ versions.tf                  # Provider ë²„ì „
â”œâ”€â”€ terraform.tfvars.example     # ì„¤ì • ì˜ˆì‹œ íŒŒì¼
â”‚
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ vpc/                     # VPC ëª¨ë“ˆ
â”‚   â”‚   â”œâ”€â”€ main.tf
â”‚   â”‚   â”œâ”€â”€ variables.tf
â”‚   â”‚   â””â”€â”€ outputs.tf
â”‚   â”‚
â”‚   â”œâ”€â”€ ec2/                     # EC2 ëª¨ë“ˆ
â”‚   â”‚   â”œâ”€â”€ main.tf
â”‚   â”‚   â”œâ”€â”€ user_data.sh         # ì´ˆê¸°í™” ìŠ¤í¬ë¦½íŠ¸
â”‚   â”‚   â”œâ”€â”€ variables.tf
â”‚   â”‚   â””â”€â”€ outputs.tf
â”‚   â”‚
â”‚   â”œâ”€â”€ rds/                     # RDS ëª¨ë“ˆ
â”‚   â”œâ”€â”€ s3/                      # S3 ëª¨ë“ˆ
â”‚   â”œâ”€â”€ cloudwatch/              # CloudWatch ëª¨ë“ˆ
â”‚   â”œâ”€â”€ sns/                     # SNS ëª¨ë“ˆ
â”‚   â””â”€â”€ lambda/                  # Lambda ëª¨ë“ˆ
â”‚
â””â”€â”€ examples/                    # ì‚¬ìš© ì˜ˆì‹œ
    â”œâ”€â”€ 01-s3-only/
    â”œâ”€â”€ 02-vpc-ec2/
    â”œâ”€â”€ 03-full-stack/
    â””â”€â”€ 04-serverless/
```

---

## ë¹ ë¥¸ ì‹œì‘

### 1. ì „ì²´ ì¸í”„ë¼ í•œë²ˆì— ìƒì„±

```
# 1. terraform.tfvars íŒŒì¼ ìƒì„±
cp terraform.tfvars.example terraform.tfvars

# 2. íŒŒì¼ ìˆ˜ì • (ì›í•˜ëŠ” ì„œë¹„ìŠ¤ í™œì„±í™”)
vim terraform.tfvars

# 3. Terraform ì´ˆê¸°í™”
terraform init

# 4. ì‹¤í–‰ ê³„íš í™•ì¸
terraform plan

# 5. ì¸í”„ë¼ ìƒì„±
terraform apply

# 6. ìƒì„±ëœ ë¦¬ì†ŒìŠ¤ í™•ì¸
terraform output
```

### 2. ìµœì†Œ ì„¤ì • ì˜ˆì‹œ (S3ë§Œ ìƒì„±)

`terraform.tfvars` íŒŒì¼:

```
project_name = "my-project"
environment  = "dev"
aws_region   = "ap-northeast-2"

# S3ë§Œ í™œì„±í™”
enable_s3 = true

s3_buckets = {
  "data-storage" = {
    versioning_enabled = true
    enable_encryption  = true
    lifecycle_rules    = []
  }
}
```

```
terraform init
terraform apply -auto-approve
```

---

## ê°œë³„ ì„œë¹„ìŠ¤ ìƒì„± ë°©ë²•

### 1ï¸âƒ£ S3 ë²„í‚·ë§Œ ìƒì„±

**ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤**: ìŠ¤í† ë¦¬ì§€ë§Œ í•„ìš”í•œ ê²½ìš° (ë…ë¦½ ì‹¤í–‰ ê°€ëŠ¥)[web:93][web:94]

**terraform.tfvars**:
```
project_name = "storage-project"
environment  = "prod"
aws_region   = "ap-northeast-2"

# S3ë§Œ í™œì„±í™”
enable_s3 = true

# ì—¬ëŸ¬ ë²„í‚· ë™ì‹œ ìƒì„± ê°€ëŠ¥
s3_buckets = {
  "user-uploads" = {
    versioning_enabled = true
    enable_encryption  = true
    lifecycle_rules = [
      {
        id                       = "delete-old-files"
        enabled                  = true
        expiration_days          = 90
        transition_days          = 30
        transition_storage_class = "STANDARD_IA"
      }
    ]
  },
  "app-logs" = {
    versioning_enabled = false
    enable_encryption  = true
    lifecycle_rules = [
      {
        id                       = "archive-logs"
        enabled                  = true
        expiration_days          = 365
        transition_days          = 90
        transition_storage_class = "GLACIER"
      }
    ]
  },
  "backup-data" = {
    versioning_enabled = true
    enable_encryption  = true
    lifecycle_rules    = []
  }
}
```

**ì‹¤í–‰**:
```
terraform init
terraform plan
terraform apply

# íŠ¹ì • ë²„í‚·ë§Œ ìƒì„±í•˜ë ¤ë©´
terraform apply -target='module.s3["user-uploads"]'

# ì¶œë ¥ í™•ì¸
terraform output
```

**ì˜ˆìƒ ì¶œë ¥**:
```
s3_bucket_name_user-uploads = "storage-project-prod-user-uploads"
s3_bucket_arn_user-uploads  = "arn:aws:s3:::storage-project-prod-user-uploads"
```

---

### 2ï¸âƒ£ CloudWatch + SNSë§Œ ìƒì„± (ëª¨ë‹ˆí„°ë§ ì „ìš©)

**ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤**: ê¸°ì¡´ ì¸í”„ë¼ì— ëª¨ë‹ˆí„°ë§ ì¶”ê°€[web:89]

**terraform.tfvars**:
```
project_name = "monitoring"
environment  = "prod"
aws_region   = "ap-northeast-2"

enable_cloudwatch = true
enable_sns        = true

# CloudWatch ì„¤ì •
log_retention_days = 30

# SNS ì„¤ì •
sns_topic_name = "infrastructure-alerts"
sns_email_endpoints = [
  "devops@company.com",
  "oncall@company.com"
]
```

**ì‹¤í–‰**:
```
terraform init
terraform apply

# CloudWatch ë¡œê·¸ ê·¸ë£¹ í™•ì¸
aws logs describe-log-groups --log-group-name-prefix "/aws/monitoring"

# SNS í† í”½ í™•ì¸
aws sns list-topics
```

---

### 3ï¸âƒ£ Lambda í•¨ìˆ˜ë§Œ ìƒì„± (ì„œë²„ë¦¬ìŠ¤)

**ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤**: ì„œë²„ë¦¬ìŠ¤ ì• í”Œë¦¬ì¼€ì´ì…˜[web:92]

**terraform.tfvars**:
```
project_name = "serverless-api"
environment  = "dev"
aws_region   = "ap-northeast-2"

enable_lambda = true

lambda_functions = {
  "image-processor" = {
    runtime          = "python3.11"
    handler          = "lambda_function.handler"
    source_code_path = "./lambda/image-processor"
    memory_size      = 1024
    timeout          = 300
    environment_vars = {
      BUCKET_NAME = "my-bucket"
      MAX_SIZE    = "5242880"
    }
    enable_s3_access  = false
    enable_vpc_access = false
  },
  "data-validator" = {
    runtime          = "python3.11"
    handler          = "index.handler"
    source_code_path = "./lambda/validator"
    memory_size      = 512
    timeout          = 60
    environment_vars = {
      API_ENDPOINT = "https://api.example.com"
    }
    enable_s3_access  = false
    enable_vpc_access = false
  }
}
```

**Lambda ì½”ë“œ ì¤€ë¹„**:
```
# Lambda ì†ŒìŠ¤ ì½”ë“œ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p lambda/image-processor
cat > lambda/image-processor/lambda_function.py <<EOF
def handler(event, context):
    print("Image processing started")
    return {"statusCode": 200, "body": "Success"}
EOF

# íŒ¨í‚¤ì§• (Terraformì´ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•˜ì§€ë§Œ ë¯¸ë¦¬ í™•ì¸ ê°€ëŠ¥)
cd lambda/image-processor
zip -r ../image-processor.zip .
cd ../..
```

**ì‹¤í–‰**:
```
terraform init
terraform apply

# íŠ¹ì • Lambdaë§Œ ìƒì„±
terraform apply -target='module.lambda["image-processor"]'

# Lambda í•¨ìˆ˜ í…ŒìŠ¤íŠ¸
aws lambda invoke \
  --function-name serverless-api-dev-image-processor \
  --payload '{"test": "data"}' \
  response.json
```

---

### 4ï¸âƒ£ RDSë§Œ ìƒì„± (ê¸°ì¡´ VPC ì‚¬ìš©)

**ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤**: ê¸°ì¡´ VPCì— ë°ì´í„°ë² ì´ìŠ¤ ì¶”ê°€[web:13]

**ì‚¬ì „ ìš”êµ¬ì‚¬í•­**: ê¸°ì¡´ VPCì™€ Private Subnet ID í•„ìš”

```
# ê¸°ì¡´ VPC ì •ë³´ ì¡°íšŒ
aws ec2 describe-vpcs
aws ec2 describe-subnets --filters "Name=vpc-id,Values=vpc-xxxxx"
```

**terraform.tfvars**:
```
project_name = "database-cluster"
environment  = "prod"
aws_region   = "ap-northeast-2"

# VPC ìƒì„± ë¹„í™œì„±í™”, ê¸°ì¡´ VPC ì‚¬ìš©
enable_vpc = false
existing_vpc_id = "vpc-0a1b2c3d4e5f6g7h8"
existing_private_subnet_ids = [
  "subnet-0123456789abcdef0",
  "subnet-abcdef0123456789a"
]

# RDS í™œì„±í™”
enable_rds = true

rds_instances = {
  "master-db" = {
    engine            = "mysql"
    engine_version    = "8.0.35"
    instance_class    = "db.r5.large"
    allocated_storage = 100
    db_name           = "production"
    username          = "admin"
    password          = "SuperSecurePassword123!"  # ì‹¤ì œë¡œëŠ” AWS Secrets Manager ê¶Œì¥
    enable_s3_backup  = false
  },
  "analytics-db" = {
    engine            = "postgres"
    engine_version    = "15.3"
    instance_class    = "db.t3.medium"
    allocated_storage = 50
    db_name           = "analytics"
    username          = "admin"
    password          = "AnotherSecurePass456!"
    enable_s3_backup  = false
  }
}
```

**ì‹¤í–‰**:
```
terraform init
terraform apply

# íŠ¹ì • RDSë§Œ ìƒì„±
terraform apply -target='module.rds["master-db"]'

# RDS ì—”ë“œí¬ì¸íŠ¸ í™•ì¸
terraform output | grep rds_endpoint
```

**ì—°ê²° í…ŒìŠ¤íŠ¸**:
```
# MySQL ì—°ê²°
mysql -h <rds_endpoint> -u admin -p production

# PostgreSQL ì—°ê²°
psql -h <rds_endpoint> -U admin -d analytics
```

---

### 5ï¸âƒ£ VPCë§Œ ìƒì„± (ë„¤íŠ¸ì›Œí¬ ê¸°ë°˜)

**ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤**: ë„¤íŠ¸ì›Œí¬ ì¸í”„ë¼ ë¨¼ì € êµ¬ì¶•[web:89]

**terraform.tfvars**:
```
project_name = "network-foundation"
environment  = "prod"
aws_region   = "ap-northeast-2"

enable_vpc = true

# VPC ì„¤ì •
vpc_cidr = "10.0.0.0/16"
availability_zones = [
  "ap-northeast-2a",
  "ap-northeast-2b",
  "ap-northeast-2c"
]
public_subnet_cidrs = [
  "10.0.1.0/24",
  "10.0.2.0/24",
  "10.0.3.0/24"
]
private_subnet_cidrs = [
  "10.0.11.0/24",
  "10.0.12.0/24",
  "10.0.13.0/24"
]
enable_nat_gateway = true
```

**ì‹¤í–‰**:
```
terraform init
terraform apply

# VPC ì •ë³´ ì €ì¥ (ë‹¤ìŒ ë‹¨ê³„ì—ì„œ ì‚¬ìš©)
terraform output vpc_id > vpc_info.txt
terraform output private_subnet_ids >> vpc_info.txt
terraform output public_subnet_ids >> vpc_info.txt
```

---

## íŒŒë¼ë¯¸í„° ìƒì„¸ ì„¤ëª…

### ì „ì—­ íŒŒë¼ë¯¸í„°

| íŒŒë¼ë¯¸í„° | íƒ€ì… | í•„ìˆ˜ | ê¸°ë³¸ê°’ | ì„¤ëª… |
|---------|------|------|--------|------|
| `project_name` | string | âœ… | - | í”„ë¡œì íŠ¸ ì´ë¦„ (ëª¨ë“  ë¦¬ì†ŒìŠ¤ ì´ë¦„ì— í¬í•¨) |
| `environment` | string | âœ… | - | í™˜ê²½ (dev, staging, prod) |
| `aws_region` | string | âŒ | `ap-northeast-2` | AWS ë¦¬ì „ |
| `key_name` | string | âŒ | `""` | EC2 SSH í‚¤ í˜ì–´ ì´ë¦„ |

### ì„œë¹„ìŠ¤ í™œì„±í™” í”Œë˜ê·¸

| íŒŒë¼ë¯¸í„° | íƒ€ì… | ê¸°ë³¸ê°’ | ì„¤ëª… |
|---------|------|--------|------|
| `enable_vpc` | bool | `false` | VPC ìƒì„± ì—¬ë¶€ |
| `enable_ec2` | bool | `false` | EC2 ìƒì„± ì—¬ë¶€ |
| `enable_rds` | bool | `false` | RDS ìƒì„± ì—¬ë¶€ |
| `enable_s3` | bool | `false` | S3 ìƒì„± ì—¬ë¶€ |
| `enable_cloudwatch` | bool | `false` | CloudWatch ìƒì„± ì—¬ë¶€ |
| `enable_sns` | bool | `false` | SNS ìƒì„± ì—¬ë¶€ |
| `enable_lambda` | bool | `false` | Lambda ìƒì„± ì—¬ë¶€ |

### VPC íŒŒë¼ë¯¸í„°

```
variable "vpc_cidr" {
  description = "VPC CIDR ë¸”ë¡"
  type        = string
  default     = "10.0.0.0/16"
}

variable "availability_zones" {
  description = "ì‚¬ìš©í•  ê°€ìš© ì˜ì—­ ëª©ë¡"
  type        = list(string)
  default     = ["ap-northeast-2a", "ap-northeast-2c"]
}

variable "public_subnet_cidrs" {
  description = "í¼ë¸”ë¦­ ì„œë¸Œë„· CIDR ëª©ë¡"
  type        = list(string)
  default     = ["10.0.1.0/24", "10.0.2.0/24"]
}

variable "private_subnet_cidrs" {
  description = "í”„ë¼ì´ë¹— ì„œë¸Œë„· CIDR ëª©ë¡"
  type        = list(string)
  default     = ["10.0.11.0/24", "10.0.12.0/24"]
}

variable "enable_nat_gateway" {
  description = "NAT Gateway ìƒì„± ì—¬ë¶€ (í”„ë¼ì´ë¹— ì„œë¸Œë„· ì¸í„°ë„· ì ‘ê·¼)"
  type        = bool
  default     = true
}
```

### EC2 íŒŒë¼ë¯¸í„°

```
variable "ec2_instances" {
  description = "ìƒì„±í•  EC2 ì¸ìŠ¤í„´ìŠ¤ ë§µ"
  type = map(object({
    instance_type          = string  # t3.micro, t3.small, t3.medium ë“±
    ami_id                 = string  # Amazon Linux 2023: ami-0c9c942bd7bf113a2
    enable_s3_access       = bool    # S3 ë²„í‚· ì ‘ê·¼ ê¶Œí•œ ë¶€ì—¬
    enable_rds_access      = bool    # RDS ì ‘ê·¼ ë³´ì•ˆ ê·¸ë£¹ ì„¤ì •
    enable_cloudwatch_logs = bool    # CloudWatch Logs ìë™ ìˆ˜ì§‘
  }))
  default = {}
}
```

**AMI ID ì¡°íšŒ**:
```
# Amazon Linux 2023 ìµœì‹  AMI
aws ec2 describe-images \
  --owners amazon \
  --filters "Name=name,Values=al2023-ami-*-x86_64" \
  --query 'sort_by(Images, &CreationDate)[-1].ImageId' \
  --output text

# Ubuntu 22.04 LTS ìµœì‹  AMI
aws ec2 describe-images \
  --owners 099720109477 \
  --filters "Name=name,Values=ubuntu/images/hvm-ssd/ubuntu-jammy-22.04-amd64-server-*" \
  --query 'sort_by(Images, &CreationDate)[-1].ImageId' \
  --output text
```

### RDS íŒŒë¼ë¯¸í„°

```
variable "rds_instances" {
  type = map(object({
    engine            = string  # mysql, postgres, mariadb, aurora-mysql ë“±
    engine_version    = string  # MySQL: 8.0.35, PostgreSQL: 15.3
    instance_class    = string  # db.t3.micro, db.t3.small, db.r5.large ë“±
    allocated_storage = number  # GB ë‹¨ìœ„ (ìµœì†Œ 20)
    db_name           = string  # ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„
    username          = string  # ë§ˆìŠ¤í„° ì‚¬ìš©ì ì´ë¦„
    password          = string  # ë§ˆìŠ¤í„° ë¹„ë°€ë²ˆí˜¸ (ìµœì†Œ 8ì)
    enable_s3_backup  = bool    # S3 ë°±ì—… í™œì„±í™” ì—¬ë¶€
  }))
  default   = {}
  sensitive = true  # ë¹„ë°€ë²ˆí˜¸ ë³´í˜¸
}
```

**ì—”ì§„ ë²„ì „ ì¡°íšŒ**:
```
# MySQL ì‚¬ìš© ê°€ëŠ¥ ë²„ì „
aws rds describe-db-engine-versions \
  --engine mysql \
  --query 'DBEngineVersions[*].EngineVersion' \
  --output table

# PostgreSQL ì‚¬ìš© ê°€ëŠ¥ ë²„ì „
aws rds describe-db-engine-versions \
  --engine postgres \
  --query 'DBEngineVersions[*].EngineVersion' \
  --output table
```

### S3 íŒŒë¼ë¯¸í„°

```
variable "s3_buckets" {
  type = map(object({
    versioning_enabled = bool  # ë²„ì „ ê´€ë¦¬ í™œì„±í™”
    enable_encryption  = bool  # ì„œë²„ ì¸¡ ì•”í˜¸í™” (AES256)
    lifecycle_rules = list(object({
      id                       = string  # ê·œì¹™ ì´ë¦„
      enabled                  = bool    # ê·œì¹™ í™œì„±í™” ì—¬ë¶€
      expiration_days          = number  # ì¼ í›„ ì‚­ì œ
      transition_days          = number  # ì¼ í›„ ì „í™˜
      transition_storage_class = string  # STANDARD_IA, GLACIER ë“±
    }))
  }))
  default = {}
}
```

### CloudWatch íŒŒë¼ë¯¸í„°

```
variable "log_retention_days" {
  description = "ë¡œê·¸ ë³´ê´€ ê¸°ê°„ (ì¼)"
  type        = number
  default     = 7
  # ê°€ëŠ¥í•œ ê°’: 1, 3, 5, 7, 14, 30, 60, 90, 120, 150, 180, 365, 400, 545, 731, 1827, 3653
}
```

### SNS íŒŒë¼ë¯¸í„°

```
variable "sns_topic_name" {
  description = "SNS í† í”½ ì´ë¦„"
  type        = string
  default     = "infrastructure-alerts"
}

variable "sns_email_endpoints" {
  description = "ì•Œë¦¼ ìˆ˜ì‹  ì´ë©”ì¼ ì£¼ì†Œ ëª©ë¡"
  type        = list(string)
  default     = []
  # ì˜ˆ: ["admin@example.com", "oncall@example.com"]
}
```

### Lambda íŒŒë¼ë¯¸í„°

```
variable "lambda_functions" {
  type = map(object({
    runtime           = string           # python3.11, nodejs18.x, java17 ë“±
    handler           = string           # lambda_function.handler
    source_code_path  = string           # ./lambda/function-name
    memory_size       = number           # MB (128 ~ 10240)
    timeout           = number           # ì´ˆ (ìµœëŒ€ 900)
    environment_vars  = map(string)      # í™˜ê²½ ë³€ìˆ˜
    enable_s3_access  = bool             # S3 ì ‘ê·¼ ê¶Œí•œ
    enable_vpc_access = bool             # VPC ë‚´ë¶€ ì‹¤í–‰
  }))
  default = {}
}
```

---

## ì—°ê²°ëœ ì¸í”„ë¼ ìƒì„± ì˜ˆì‹œ

### ì˜ˆì‹œ 1: ì›¹ ì„œë²„ + ë°ì´í„°ë² ì´ìŠ¤ + ìŠ¤í† ë¦¬ì§€ (3-Tier Architecture)

**êµ¬ì„±**: VPC â†’ EC2 (Web) â†’ RDS (MySQL) â†’ S3 (Storage) + CloudWatch (Monitoring)[web:92]

**terraform.tfvars**:
```
project_name = "web-app"
environment  = "prod"
aws_region   = "ap-northeast-2"
key_name     = "my-key"

# ëª¨ë“  ì„œë¹„ìŠ¤ í™œì„±í™”
enable_vpc        = true
enable_ec2        = true
enable_rds        = true
enable_s3         = true
enable_cloudwatch = true
enable_sns        = true

# VPC ì„¤ì •
vpc_cidr             = "10.0.0.0/16"
availability_zones   = ["ap-northeast-2a", "ap-northeast-2c"]
public_subnet_cidrs  = ["10.0.1.0/24", "10.0.2.0/24"]
private_subnet_cidrs = ["10.0.11.0/24", "10.0.12.0/24"]
enable_nat_gateway   = true

# EC2 ì›¹ ì„œë²„ (ëª¨ë“  ì—°ê²° í™œì„±í™”)
ec2_instances = {
  "web-server-1" = {
    instance_type          = "t3.medium"
    ami_id                 = "ami-0c9c942bd7bf113a2"
    enable_s3_access       = true   # S3 ì—…ë¡œë“œ/ë‹¤ìš´ë¡œë“œ
    enable_rds_access      = true   # DB ì—°ê²°
    enable_cloudwatch_logs = true   # ë¡œê·¸ ìˆ˜ì§‘
  },
  "web-server-2" = {
    instance_type          = "t3.medium"
    ami_id                 = "ami-0c9c942bd7bf113a2"
    enable_s3_access       = true
    enable_rds_access      = true
    enable_cloudwatch_logs = true
  }
}

# RDS MySQL ë°ì´í„°ë² ì´ìŠ¤
rds_instances = {
  "main-db" = {
    engine            = "mysql"
    engine_version    = "8.0.35"
    instance_class    = "db.t3.medium"
    allocated_storage = 100
    db_name           = "webapp"
    username          = "admin"
    password          = "YourSecurePassword123!"
    enable_s3_backup  = true  # S3ë¡œ ë°±ì—…
  }
}

# S3 ìŠ¤í† ë¦¬ì§€
s3_buckets = {
  "user-uploads" = {
    versioning_enabled = true
    enable_encryption  = true
    lifecycle_rules = [
      {
        id                       = "archive-old-uploads"
        enabled                  = true
        expiration_days          = 365
        transition_days          = 90
        transition_storage_class = "GLACIER"
      }
    ]
  },
  "app-backups" = {
    versioning_enabled = true
    enable_encryption  = true
    lifecycle_rules    = []
  }
}

# CloudWatch ëª¨ë‹ˆí„°ë§
log_retention_days = 30

# SNS ì•Œë¦¼
sns_topic_name = "webapp-alerts"
sns_email_endpoints = ["devops@company.com"]
```

**ì‹¤í–‰ ë° ë°°í¬**:
```
# 1. ì´ˆê¸°í™”
terraform init

# 2. ì‹¤í–‰ ê³„íš í™•ì¸ (ì–´ë–¤ ë¦¬ì†ŒìŠ¤ê°€ ìƒì„±ë˜ëŠ”ì§€ í™•ì¸)
terraform plan -out=tfplan

# 3. ë‹¨ê³„ë³„ ìƒì„± (ì•ˆì „)
# ë‹¨ê³„ 1: VPC ë¨¼ì €
terraform apply -target=module.vpc

# ë‹¨ê³„ 2: S3ì™€ CloudWatch (ë…ë¦½ì )
terraform apply -target=module.s3 -target=module.cloudwatch

# ë‹¨ê³„ 3: RDS
terraform apply -target=module.rds

# ë‹¨ê³„ 4: EC2 (ëª¨ë“  ì—°ê²° ìë™ ì„¤ì •)
terraform apply -target=module.ec2

# ë‹¨ê³„ 5: SNS
terraform apply -target=module.sns

# ë˜ëŠ” í•œë²ˆì— ìƒì„±
terraform apply -auto-approve

# 4. ìƒì„±ëœ ë¦¬ì†ŒìŠ¤ ì •ë³´ í™•ì¸
terraform output
```

**ì¶œë ¥ ê²°ê³¼**:
```
ec2_public_ip_web-server-1 = "13.125.123.45"
ec2_public_ip_web-server-2 = "13.125.123.46"
rds_endpoint_main-db = "webapp-prod-main-db.xxxxx.ap-northeast-2.rds.amazonaws.com:3306"
s3_bucket_name_user-uploads = "web-app-prod-user-uploads"
cloudwatch_log_group_name = "/aws/web-app/prod"
```

**EC2ì—ì„œ RDS ì—°ê²° í…ŒìŠ¤íŠ¸**:
```
# EC2ì— SSH ì ‘ì†
ssh -i ~/.ssh/my-key.pem ec2-user@13.125.123.45

# RDS ì—°ê²° í™•ì¸ (ì—°ê²° ì •ë³´ëŠ” /home/ec2-user/rds-connection.txtì— ì €ì¥ë¨)
cat /home/ec2-user/rds-connection.txt

# MySQL í´ë¼ì´ì–¸íŠ¸ ì„¤ì¹˜ ë° ì—°ê²°
sudo yum install -y mysql
mysql -h webapp-prod-main-db.xxxxx.ap-northeast-2.rds.amazonaws.com \
      -u admin -p webapp

# S3 ì ‘ê·¼ í…ŒìŠ¤íŠ¸
aws s3 ls s3://web-app-prod-user-uploads/
echo "test" > test.txt
aws s3 cp test.txt s3://web-app-prod-user-uploads/

# CloudWatch ë¡œê·¸ í™•ì¸
tail -f /var/log/messages
# ë¡œê·¸ê°€ CloudWatchë¡œ ìë™ ì „ì†¡ë¨
```

---

### ì˜ˆì‹œ 2: ì„œë²„ë¦¬ìŠ¤ ë°ì´í„° íŒŒì´í”„ë¼ì¸

**êµ¬ì„±**: S3 (Input) â†’ Lambda (Processing) â†’ S3 (Output) + SNS (Notification)[web:89]

**terraform.tfvars**:
```
project_name = "data-pipeline"
environment  = "prod"
aws_region   = "ap-northeast-2"

enable_s3     = true
enable_lambda = true
enable_sns    = true

# S3 ë²„í‚·
s3_buckets = {
  "input-data" = {
    versioning_enabled = true
    enable_encryption  = true
    lifecycle_rules    = []
  },
  "processed-data" = {
    versioning_enabled = true
    enable_encryption  = true
    lifecycle_rules = [
      {
        id                       = "archive-processed"
        enabled                  = true
        expiration_days          = 180
        transition_days          = 30
        transition_storage_class = "GLACIER"
      }
    ]
  }
}

# Lambda í•¨ìˆ˜ (S3 ì ‘ê·¼ ê°€ëŠ¥)
lambda_functions = {
  "csv-processor" = {
    runtime          = "python3.11"
    handler          = "lambda_function.handler"
    source_code_path = "./lambda/csv-processor"
    memory_size      = 2048
    timeout          = 300
    environment_vars = {
      INPUT_BUCKET  = "data-pipeline-prod-input-data"
      OUTPUT_BUCKET = "data-pipeline-prod-processed-data"
    }
    enable_s3_access  = true
    enable_vpc_access = false
  },
  "data-validator" = {
    runtime          = "python3.11"
    handler          = "index.handler"
    source_code_path = "./lambda/validator"
    memory_size      = 1024
    timeout          = 120
    environment_vars = {
      SNS_TOPIC_ARN = "arn:aws:sns:ap-northeast-2:123456789012:data-pipeline-prod-alerts"
    }
    enable_s3_access  = true
    enable_vpc_access = false
  }
}

# SNS ì•Œë¦¼
sns_topic_name = "data-pipeline-alerts"
sns_email_endpoints = ["data-team@company.com"]
```

**Lambda í•¨ìˆ˜ ì½”ë“œ ì¤€ë¹„**:
```
# CSV Processor Lambda
mkdir -p lambda/csv-processor
cat > lambda/csv-processor/lambda_function.py <<'EOF'
import json
import boto3
import os

s3 = boto3.client('s3')

def handler(event, context):
    input_bucket = os.environ['INPUT_BUCKET']
    output_bucket = os.environ['OUTPUT_BUCKET']
    
    # S3 ì´ë²¤íŠ¸ì—ì„œ íŒŒì¼ ì •ë³´ ì¶”ì¶œ
    for record in event['Records']:
        bucket = record['s3']['bucket']['name']
        key = record['s3']['object']['key']
        
        print(f"Processing file: {key} from bucket: {bucket}")
        
        # íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        obj = s3.get_object(Bucket=bucket, Key=key)
        data = obj['Body'].read().decode('utf-8')
        
        # ë°ì´í„° ì²˜ë¦¬ (ì˜ˆì‹œ)
        processed_data = data.upper()
        
        # ê²°ê³¼ ì—…ë¡œë“œ
        output_key = f"processed/{key}"
        s3.put_object(
            Bucket=output_bucket,
            Key=output_key,
            Body=processed_data
        )
        
        print(f"Processed file saved to: {output_key}")
    
    return {
        'statusCode': 200,
        'body': json.dumps('Processing complete')
    }
EOF

# Validator Lambda
mkdir -p lambda/validator
cat > lambda/validator/index.py <<'EOF'
import json
import boto3
import os

sns = boto3.client('sns')

def handler(event, context):
    sns_topic = os.environ['SNS_TOPIC_ARN']
    
    # ê²€ì¦ ë¡œì§ (ì˜ˆì‹œ)
    is_valid = True
    
    if is_valid:
        message = "Data validation passed"
    else:
        message = "Data validation failed"
        # SNS ì•Œë¦¼ ì „ì†¡
        sns.publish(
            TopicArn=sns_topic,
            Subject='Data Validation Alert',
            Message=message
        )
    
    return {
        'statusCode': 200,
        'body': json.dumps(message)
    }
EOF
```

**ì‹¤í–‰**:
```
terraform init
terraform apply

# S3 ì´ë²¤íŠ¸ íŠ¸ë¦¬ê±° ì„¤ì • (ìˆ˜ë™)
aws s3api put-bucket-notification-configuration \
  --bucket data-pipeline-prod-input-data \
  --notification-configuration '{
    "LambdaFunctionConfigurations": [{
      "LambdaFunctionArn": "arn:aws:lambda:ap-northeast-2:123456789012:function:data-pipeline-prod-csv-processor",
      "Events": ["s3:ObjectCreated:*"]
    }]
  }'

# í…ŒìŠ¤íŠ¸
echo "test,data,123" > test.csv
aws s3 cp test.csv s3://data-pipeline-prod-input-data/

# ì²˜ë¦¬ ê²°ê³¼ í™•ì¸
aws s3 ls s3://data-pipeline-prod-processed-data/processed/
```

---

### ì˜ˆì‹œ 3: ê³ ê°€ìš©ì„± API ì„œë²„ (Multi-AZ)

**êµ¬ì„±**: VPC (3 AZ) â†’ EC2 (3ëŒ€) â†’ RDS (Multi-AZ) + CloudWatch + SNS[web:13]

**terraform.tfvars**:
```
project_name = "api-service"
environment  = "prod"
aws_region   = "ap-northeast-2"
key_name     = "api-key"

enable_vpc        = true
enable_ec2        = true
enable_rds        = true
enable_cloudwatch = true
enable_sns        = true

# VPC - 3ê°œ ê°€ìš© ì˜ì—­
vpc_cidr = "10.10.0.0/16"
availability_zones = [
  "ap-northeast-2a",
  "ap-northeast-2b",
  "ap-northeast-2c"
]
public_subnet_cidrs = [
  "10.10.1.0/24",
  "10.10.2.0/24",
  "10.10.3.0/24"
]
private_subnet_cidrs = [
  "10.10.11.0/24",
  "10.10.12.0/24",
  "10.10.13.0/24"
]
enable_nat_gateway = true

# EC2 - ê° AZì— 1ëŒ€ì”©
ec2_instances = {
  "api-server-az1" = {
    instance_type          = "t3.large"
    ami_id                 = "ami-0c9c942bd7bf113a2"
    enable_s3_access       = false
    enable_rds_access      = true
    enable_cloudwatch_logs = true
  },
  "api-server-az2" = {
    instance_type          = "t3.large"
    ami_id                 = "ami-0c9c942bd7bf113a2"
    enable_s3_access       = false
    enable_rds_access      = true
    enable_cloudwatch_logs = true
  },
  "api-server-az3" = {
    instance_type          = "t3.large"
    ami_id                 = "ami-0c9c942bd7bf113a2"
    enable_s3_access       = false
    enable_rds_access      = true
    enable_cloudwatch_logs = true
  }
}

# RDS - í”„ë¡œë•ì…˜ ì„¤ì •
rds_instances = {
  "api-db" = {
    engine            = "postgres"
    engine_version    = "15.3"
    instance_class    = "db.r5.xlarge"
    allocated_storage = 200
    db_name           = "apidb"
    username          = "dbadmin"
    password          = "VerySecurePassword123!"
    enable_s3_backup  = false
  }
}

# CloudWatch
log_retention_days = 90

# SNS
sns_topic_name = "api-service-alerts"
sns_email_endpoints = [
  "sre@company.com",
  "oncall@company.com"
]
```

**ì‹¤í–‰ ë° ë¡œë“œ ë°¸ëŸ°ì„œ ì¶”ê°€** (ì„ íƒì‚¬í•­):
```
terraform apply

# ìƒì„±ëœ EC2 IP í™•ì¸
terraform output | grep ec2_public_ip

# ìˆ˜ë™ìœ¼ë¡œ ALB ì¶”ê°€ (Terraform ì™¸ë¶€)
aws elbv2 create-load-balancer \
  --name api-service-alb \
  --subnets subnet-xxx subnet-yyy subnet-zzz \
  --security-groups sg-xxxxx
```

---

## ê³ ê¸‰ ì‚¬ìš©ë²•

### 1. íŠ¹ì • ë¦¬ì†ŒìŠ¤ë§Œ ìƒì„±/ì‚­ì œ

```
# S3 ë²„í‚· 1ê°œë§Œ ìƒì„±
terraform apply -target='module.s3["user-uploads"]'

# EC2 ì¸ìŠ¤í„´ìŠ¤ 1ëŒ€ë§Œ ìƒì„±
terraform apply -target='module.ec2["web-server-1"]'

# RDS 1ê°œë§Œ ì‚­ì œ
terraform destroy -target='module.rds["analytics-db"]'

# CloudWatchë§Œ ì—…ë°ì´íŠ¸
terraform apply -target=module.cloudwatch
```

### 2. ë³€ìˆ˜ íŒŒì¼ ë¶„ë¦¬ ê´€ë¦¬

```
# í™˜ê²½ë³„ ë³€ìˆ˜ íŒŒì¼ ìƒì„±
terraform-infra-builder/
â”œâ”€â”€ environments/
â”‚   â”œâ”€â”€ dev.tfvars
â”‚   â”œâ”€â”€ staging.tfvars
â”‚   â””â”€â”€ prod.tfvars

# Dev í™˜ê²½ ë°°í¬
terraform apply -var-file=environments/dev.tfvars

# Prod í™˜ê²½ ë°°í¬
terraform apply -var-file=environments/prod.tfvars
```

**dev.tfvars**:
```
project_name = "myapp"
environment  = "dev"
enable_vpc   = true
enable_ec2   = true

ec2_instances = {
  "dev-server" = {
    instance_type          = "t3.small"  # ê°œë°œì€ ì‘ì€ ì¸ìŠ¤í„´ìŠ¤
    ami_id                 = "ami-0c9c942bd7bf113a2"
    enable_s3_access       = true
    enable_rds_access      = false
    enable_cloudwatch_logs = false
  }
}
```

**prod.tfvars**:
```
project_name = "myapp"
environment  = "prod"
enable_vpc   = true
enable_ec2   = true

ec2_instances = {
  "prod-server-1" = {
    instance_type          = "t3.large"  # í”„ë¡œë•ì…˜ì€ í° ì¸ìŠ¤í„´ìŠ¤
    ami_id                 = "ami-0c9c942bd7bf113a2"
    enable_s3_access       = true
    enable_rds_access      = true
    enable_cloudwatch_logs = true
  },
  "prod-server-2" = {
    instance_type          = "t3.large"
    ami_id                 = "ami-0c9c942bd7bf113a2"
    enable_s3_access       = true
    enable_rds_access      = true
    enable_cloudwatch_logs = true
  }
}
```

### 3. State íŒŒì¼ ì›ê²© ì €ì¥ (íŒ€ í˜‘ì—…)

**backend.tf** ìƒì„±:
```
terraform {
  backend "s3" {
    bucket         = "my-terraform-state-bucket"
    key            = "infrastructure/terraform.tfstate"
    region         = "ap-northeast-2"
    encrypt        = true
    dynamodb_table = "terraform-lock-table"
  }
}
```

**S3 ë²„í‚· ë° DynamoDB í…Œì´ë¸” ìƒì„±**:
```
# S3 ë²„í‚· ìƒì„±
aws s3api create-bucket \
  --bucket my-terraform-state-bucket \
  --region ap-northeast-2 \
  --create-bucket-configuration LocationConstraint=ap-northeast-2

# ë²„í‚· ë²„ì €ë‹ í™œì„±í™”
aws s3api put-bucket-versioning \
  --bucket my-terraform-state-bucket \
  --versioning-configuration Status=Enabled

# DynamoDB ë½ í…Œì´ë¸” ìƒì„±
aws dynamodb create-table \
  --table-name terraform-lock-table \
  --attribute-definitions AttributeName=LockID,AttributeType=S \
  --key-schema AttributeName=LockID,KeyType=HASH \
  --billing-mode PAY_PER_REQUEST \
  --region ap-northeast-2

# State ë§ˆì´ê·¸ë ˆì´ì…˜
terraform init -migrate-state
```

### 4. ë¦¬ì†ŒìŠ¤ Import (ê¸°ì¡´ ë¦¬ì†ŒìŠ¤ ê°€ì ¸ì˜¤ê¸°)

```
# ê¸°ì¡´ S3 ë²„í‚· ê°€ì ¸ì˜¤ê¸°
terraform import 'module.s3["existing-bucket"].aws_s3_bucket.this' existing-bucket-name

# ê¸°ì¡´ EC2 ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
terraform import 'module.ec2["imported-server"].aws_instance.this' i-1234567890abcdef0

# ê¸°ì¡´ VPC ê°€ì ¸ì˜¤ê¸°
terraform import 'module.vpc.aws_vpc.this' vpc-0a1b2c3d
```

### 5. Output ê°’ ì¡°íšŒ ë° í™œìš©

```
# ëª¨ë“  ì¶œë ¥ ê°’ ì¡°íšŒ
terraform output

# íŠ¹ì • ì¶œë ¥ ê°’ë§Œ ì¡°íšŒ
terraform output ec2_public_ip_web-server-1

# JSON í˜•ì‹ìœ¼ë¡œ ì¡°íšŒ
terraform output -json

# ë‹¤ë¥¸ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì‚¬ìš©
WEB_SERVER_IP=$(terraform output -raw ec2_public_ip_web-server-1)
echo "Web server IP: $WEB_SERVER_IP"

# ì¶œë ¥ ê°’ìœ¼ë¡œ SSH ì ‘ì†
ssh -i ~/.ssh/my-key.pem ec2-user@$(terraform output -raw ec2_public_ip_web-server-1)
```

---

## íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ë¬¸ì œ 1: "Error: Error launching source instance"

**ì›ì¸**: AMI IDê°€ í•´ë‹¹ ë¦¬ì „ì— ì¡´ì¬í•˜ì§€ ì•ŠìŒ

**í•´ê²°**:
```
# í˜„ì¬ ë¦¬ì „ì˜ Amazon Linux 2023 AMI ì¡°íšŒ
aws ec2 describe-images \
  --owners amazon \
  --filters "Name=name,Values=al2023-ami-*-x86_64" \
  --region ap-northeast-2 \
  --query 'Images.ImageId' \
  --output text

# terraform.tfvarsì— ì˜¬ë°”ë¥¸ AMI ID ì…ë ¥
```

### ë¬¸ì œ 2: "Error creating DB Instance: InvalidVPCNetworkStateFault"

**ì›ì¸**: Private Subnetì— ë¼ìš°íŒ…ì´ ì—†ê±°ë‚˜ ì„œë¸Œë„· ê°œìˆ˜ ë¶€ì¡±

**í•´ê²°**:
```
# ìµœì†Œ 2ê°œì˜ ë‹¤ë¥¸ ê°€ìš© ì˜ì—­ ì„œë¸Œë„· í•„ìš”
private_subnet_cidrs = [
  "10.0.11.0/24",  # AZ-a
  "10.0.12.0/24"   # AZ-c
]

# NAT Gateway í™œì„±í™”
enable_nat_gateway = true
```

### ë¬¸ì œ 3: EC2ì—ì„œ RDS ì—°ê²° ì‹¤íŒ¨

**ì›ì¸**: Security Group ê·œì¹™ì´ ì œëŒ€ë¡œ ì„¤ì •ë˜ì§€ ì•ŠìŒ

**í™•ì¸**:
```
# RDS Security Group Inbound ê·œì¹™ í™•ì¸
aws ec2 describe-security-groups \
  --group-ids sg-xxxxx \
  --query 'SecurityGroups.IpPermissions'

# EC2ì—ì„œ ì—°ê²° í…ŒìŠ¤íŠ¸
telnet <rds-endpoint> 3306
```

**í•´ê²°**:
```
# terraform.tfvarsì—ì„œ í™œì„±í™” í™•ì¸
ec2_instances = {
  "web-server" = {
    enable_rds_access = true  # â† ì´ ì„¤ì • í™•ì¸
  }
}
```

### ë¬¸ì œ 4: CloudWatch ë¡œê·¸ê°€ ìˆ˜ì§‘ë˜ì§€ ì•ŠìŒ

**ì›ì¸**: CloudWatch Agentê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ê±°ë‚˜ IAM ê¶Œí•œ ë¶€ì¡±

**í™•ì¸**:
```
# EC2ì— SSH ì ‘ì†
ssh -i ~/.ssh/my-key.pem ec2-user@<ec2-ip>

# CloudWatch Agent ìƒíƒœ í™•ì¸
sudo /opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-ctl \
  -a query -m ec2 -c default

# Agent ë¡œê·¸ í™•ì¸
sudo tail -f /opt/aws/amazon-cloudwatch-agent/logs/amazon-cloudwatch-agent.log

# ìˆ˜ë™ìœ¼ë¡œ ì¬ì‹œì‘
sudo /opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-ctl \
  -a fetch-config -m ec2 -s \
  -c file:/opt/aws/amazon-cloudwatch-agent/etc/config.json
```

### ë¬¸ì œ 5: Terraform state ì ê¹€ ì˜¤ë¥˜

**ì›ì¸**: ì´ì „ ì‹¤í–‰ì´ ì¤‘ë‹¨ë˜ì–´ stateê°€ ì ê¹€

**í•´ê²°**:
```
# Lock ì •ë³´ í™•ì¸
terraform force-unlock <LOCK_ID>

# ë˜ëŠ” DynamoDBì—ì„œ ì§ì ‘ ì‚­ì œ (S3 backend ì‚¬ìš© ì‹œ)
aws dynamodb delete-item \
  --table-name terraform-lock-table \
  --key '{"LockID":{"S":"my-terraform-state-bucket/infrastructure/terraform.tfstate"}}'
```

### ë¬¸ì œ 6: "Error: Insufficient capacity" (EC2 ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨)

**ì›ì¸**: í•´ë‹¹ AZì— ì„ íƒí•œ ì¸ìŠ¤í„´ìŠ¤ íƒ€ì… ìš©ëŸ‰ ë¶€ì¡±

**í•´ê²°**:
```
# ë‹¤ë¥¸ ê°€ìš© ì˜ì—­ ì‹œë„
availability_zones = [
  "ap-northeast-2b",  # ë‹¤ë¥¸ AZë¡œ ë³€ê²½
  "ap-northeast-2c"
]

# ë˜ëŠ” ë‹¤ë¥¸ ì¸ìŠ¤í„´ìŠ¤ íƒ€ì… ì„ íƒ
instance_type = "t3.medium"  # t3.large ëŒ€ì‹ 
```

### ë¬¸ì œ 7: S3 ë²„í‚· ì´ë¦„ ì¶©ëŒ

**ì›ì¸**: S3 ë²„í‚· ì´ë¦„ì€ ì „ ì„¸ê³„ì ìœ¼ë¡œ ê³ ìœ í•´ì•¼ í•¨

**í•´ê²°**:
```
# í”„ë¡œì íŠ¸ ì´ë¦„ê³¼ í™˜ê²½ì„ í¬í•¨í•˜ì—¬ ê³ ìœ ì„± ë³´ì¥
# ë²„í‚· ì´ë¦„: {project_name}-{environment}-{bucket_name}
project_name = "mycompany-webapp"  # íšŒì‚¬ëª… í¬í•¨
environment  = "prod"

s3_buckets = {
  "data-storage-20250121" = {  # ë‚ ì§œ ì¶”ê°€
    versioning_enabled = true
    enable_encryption  = true
  }
}
```

---

## ëª…ë ¹ì–´ ì¹˜íŠ¸ì‹œíŠ¸

```
# ê¸°ë³¸ ì‘ì—… íë¦„
terraform init              # ì´ˆê¸°í™”
terraform validate          # êµ¬ì„± ê²€ì¦
terraform plan              # ì‹¤í–‰ ê³„íš í™•ì¸
terraform apply             # ì¸í”„ë¼ ìƒì„±
terraform destroy           # ì¸í”„ë¼ ì‚­ì œ

# íŠ¹ì • íƒ€ê²Ÿ ì‘ì—…
terraform apply -target=MODULE.RESOURCE     # íŠ¹ì • ë¦¬ì†ŒìŠ¤ë§Œ ìƒì„±
terraform destroy -target=MODULE.RESOURCE   # íŠ¹ì • ë¦¬ì†ŒìŠ¤ë§Œ ì‚­ì œ

# ë³€ìˆ˜ íŒŒì¼ ì‚¬ìš©
terraform apply -var-file=prod.tfvars       # íŒŒì¼ì—ì„œ ë³€ìˆ˜ ë¡œë“œ
terraform apply -var="key=value"            # ëª…ë ¹ì¤„ì—ì„œ ë³€ìˆ˜ ì „ë‹¬

# Output ì¡°íšŒ
terraform output                            # ëª¨ë“  ì¶œë ¥ ì¡°íšŒ
terraform output VARIABLE_NAME              # íŠ¹ì • ì¶œë ¥ë§Œ ì¡°íšŒ
terraform output -json                      # JSON í˜•ì‹

# State ê´€ë¦¬
terraform state list                        # Stateì˜ ëª¨ë“  ë¦¬ì†ŒìŠ¤ ëª©ë¡
terraform state show MODULE.RESOURCE        # ë¦¬ì†ŒìŠ¤ ìƒì„¸ ì •ë³´
terraform state rm MODULE.RESOURCE          # Stateì—ì„œ ì œê±°
terraform import MODULE.RESOURCE ID         # ê¸°ì¡´ ë¦¬ì†ŒìŠ¤ ê°€ì ¸ì˜¤ê¸°

# í˜•ì‹ ë° ìœ íš¨ì„± ê²€ì‚¬
terraform fmt                               # ì½”ë“œ í¬ë§·íŒ…
terraform fmt -recursive                    # í•˜ìœ„ ë””ë ‰í† ë¦¬ í¬í•¨
terraform validate                          # êµ¬ë¬¸ ê²€ì¦

# Workspace ê´€ë¦¬
terraform workspace list                    # Workspace ëª©ë¡
terraform workspace new WORKSPACE_NAME      # ìƒˆ Workspace ìƒì„±
terraform workspace select WORKSPACE_NAME   # Workspace ì„ íƒ

# ê·¸ë˜í”„ ìƒì„±
terraform graph | dot -Tsvg > graph.svg     # ë¦¬ì†ŒìŠ¤ ì˜ì¡´ì„± ê·¸ë˜í”„
```

---

## ë¹„ìš© ì˜ˆì¸¡

### ìµœì†Œ êµ¬ì„± (S3ë§Œ)
- **S3 Standard**: $0.025/GB/ì›”
- **ì˜ˆìƒ ë¹„ìš©**: ~$1-5/ì›”

### ê°œë°œ í™˜ê²½ (VPC + EC2 + RDS)
- **VPC**: ë¬´ë£Œ
- **EC2 t3.small**: ~$15/ì›”
- **RDS db.t3.micro**: ~$15/ì›”
- **NAT Gateway**: ~$32/ì›”
- **ì˜ˆìƒ ë¹„ìš©**: ~$62/ì›”

### í”„ë¡œë•ì…˜ í™˜ê²½ (3-Tier)
- **EC2 t3.large (3ëŒ€)**: ~$150/ì›”
- **RDS db.r5.large**: ~$140/ì›”
- **NAT Gateway (3ê°œ)**: ~$96/ì›”
- **ALB**: ~$22/ì›”
- **S3 + CloudWatch**: ~$10/ì›”
- **ì˜ˆìƒ ë¹„ìš©**: ~$418/ì›”

**ë¹„ìš© ê³„ì‚°ê¸°**: https://calculator.aws/

---

## ë¼ì´ì„¼ìŠ¤

MIT License

---

## ì§€ì› ë° ê¸°ì—¬

- ğŸ“§ ì´ë©”ì¼: support@example.com
- ğŸ› ì´ìŠˆ: [GitHub Issues](https://github.com/your-repo/issues)
- ğŸ“– ë¬¸ì„œ: [Wiki](https://github.com/your-repo/wiki)

---

## ì°¸ê³  ìë£Œ

- [Terraform ê³µì‹ ë¬¸ì„œ](https://www.terraform.io/docs)
- [AWS Provider ë¬¸ì„œ](https://registry.terraform.io/providers/hashicorp/aws/latest/docs)
- [Terraform Best Practices](https://www.terraform-best-practices.com/)
```

***

## examples/ ë””ë ‰í† ë¦¬ êµ¬ì¡°

ê° ì˜ˆì‹œë³„ë¡œ ë…ë¦½ì ì¸ ë””ë ‰í† ë¦¬ë¥¼ ë§Œë“¤ì–´ ë°”ë¡œ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆë„ë¡ êµ¬ì„±í•©ë‹ˆë‹¤.[2][1]

```
examples/
â”œâ”€â”€ 01-s3-only/
â”‚   â”œâ”€â”€ main.tf -> ../../main.tf
â”‚   â”œâ”€â”€ variables.tf -> ../../variables.tf
â”‚   â””â”€â”€ terraform.tfvars
â”‚
â”œâ”€â”€ 02-vpc-ec2/
â”‚   â”œâ”€â”€ main.tf -> ../../main.tf
â”‚   â”œâ”€â”€ variables.tf -> ../../variables.tf
â”‚   â””â”€â”€ terraform.tfvars
â”‚
â”œâ”€â”€ 03-full-stack/
â”‚   â”œâ”€â”€ main.tf -> ../../main.tf
â”‚   â”œâ”€â”€ variables.tf -> ../../variables.tf
â”‚   â””â”€â”€ terraform.tfvars
â”‚
â””â”€â”€ 04-serverless/
    â”œâ”€â”€ main.tf -> ../../main.tf
    â”œâ”€â”€ variables.tf -> ../../variables.tf
    â””â”€â”€ terraform.tfvars
```

ê° ì˜ˆì‹œëŠ” ì‹¬ë³¼ë¦­ ë§í¬ë¡œ ë£¨íŠ¸ ëª¨ë“ˆì„ ì°¸ì¡°í•˜ê³ , `terraform.tfvars`ë§Œ ê°ê° ë‹¤ë¥´ê²Œ ì„¤ì •í•˜ë©´ ë©ë‹ˆë‹¤.[4][5]

ì´ README ë¬¸ì„œë¥¼ í†µí•´ Terraformë§Œìœ¼ë¡œë„ ëª¨ë“  ì‹œë‚˜ë¦¬ì˜¤ë¥¼ í…ŒìŠ¤íŠ¸í•˜ê³  ì‹¤ì œ ì¸í”„ë¼ë¥¼ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.[6][1][2]

[1](https://docs.cloud.google.com/docs/terraform/best-practices/general-style-structure)
[2](https://betterterraformpractices.com/getting-started/important-concepts/3readme-guide/)
[3](https://www.microtica.com/blog/terraform-modules-best-practices)
[4](https://spacelift.io/blog/terraform-tfvars)
[5](https://controlmonkey.io/resource/terraform-variables-guide/)
[6](https://developer.hashicorp.com/terraform/cloud-docs/recommended-practices)
[7](https://arxiv.org/abs/2205.10676v1)
[8](http://arxiv.org/pdf/2203.13871.pdf)
[9](https://www.frontiersin.org/articles/10.3389/fspas.2021.789563/pdf)
[10](https://linkinghub.elsevier.com/retrieve/pii/S0306437924000802)
[11](https://arxiv.org/pdf/2312.03250.pdf)
[12](http://arxiv.org/pdf/2404.18515.pdf)
[13](http://arxiv.org/pdf/2412.00726.pdf)
[14](https://arxiv.org/pdf/2201.09015.pdf)
[15](https://velog.io/@bellship24/terraform-docs%EB%A1%9C-README.md-%EC%9E%90%EB%8F%99-%EC%9E%91%EC%84%B1%ED%95%98%EB%8A%94-%EB%B0%A9%EB%B2%95)
[16](https://discuss.hashicorp.com/t/readme-md-for-terraform-module/58748)
[17](https://docs.aws.amazon.com/prescriptive-guidance/latest/terraform-aws-provider-best-practices/structure.html)
[18](https://www.youtube.com/watch?v=B6l2UbCsH94)